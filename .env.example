# GPU overlay — pick one (or omit for CPU-only)
# COMPOSE_FILE=docker-compose.yml:docker-compose.rocm.yml
# COMPOSE_FILE=docker-compose.yml:docker-compose.nvidia.yml

# Host port mapping (maps to container port 3000)
SE_PORT=3000

# External URL for OIDC redirect callbacks (must match your IdP config)
EXTERNAL_URL=http://localhost:3000

# Bootstrap admin credentials (requires BREAK_GLASS=true)
BOOTSTRAP_USER=admin
BOOTSTRAP_PASSWORD=changeme
BREAK_GLASS=false

# TLS — Option A: Automatic certs via Let's Encrypt (TLS-ALPN-01)
# ACME_DOMAIN=ai.example.com
# ACME_CONTACT=admin@example.com
# ACME_STAGING=true

# TLS — Option B: Manual certs (inside /config volume)
# TLS_CERT_PATH=/config/cert.pem
# TLS_KEY_PATH=/config/key.pem

# Model storage — host path to bind-mount as /models in containers
# Defaults to ./models if unset
# MODEL_HOST_PATH=/srv/models

# HuggingFace token (required for gated models like Llama)
# HF_TOKEN=hf_xxxxx

# Shared API key for Open WebUI ↔ proxy /v1 calls
# Generate a unique key for production: se-$(uuidgen)
WEBUI_API_KEY=se-change-me-generate-a-uuid

# Log level
RUST_LOG=sovereign_engine=info,tower_http=info
